services:
  # AI Agent service - handles API, validation, database, and LLM
  queryinator:
    build:
      context: .
      dockerfile: docker/Dockerfile.app
    ports:
      - "8000:8000"
    volumes:
      - ./graph:/app/graph
      - ./app:/app/app  # Hot reload for application
      - ./logs:/app/logs  # Persist and make logs writable
    env_file:
      - .env
    environment:
      # Override defaults for development
      - DEFAULT_LLM_PROVIDER=openai
      - SECURITY_QUERY_LOG_FILE=/app/logs/query_events.jsonl
      - SECURITY_ACCESS_LOG_FILE=/app/logs/access_audit.jsonl
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - pipe-dragon
    command: ["python", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

  # Next.js UI service - testing interface (only accessible via nginx)
  ui-unicorn:
    build:
      context: ./ui
      dockerfile: ../docker/Dockerfile.ui.dev
    # Remove direct port exposure - only accessible via nginx
    volumes:
      - ./ui:/app  # Hot reload for UI changes
      - /app/node_modules  # Prevent overwriting node_modules
    environment:
      - NL2SQL_API_URL=http://queryinator:8000
      - NEXT_PUBLIC_APP_NAME=NL2SQL AI Agent Interface
      - NEXT_PUBLIC_VERSION=1.0.0
      - NODE_ENV=development
    depends_on:
      queryinator:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - pipe-dragon
    command: ["npm", "run", "dev"]

  # Nginx reverse proxy - single entry point
  proxy-panda:
    image: nginx:alpine
    ports:
      - "7000:7000"  # Only port exposed externally
    volumes:
      - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - queryinator
      - ui-unicorn
    restart: unless-stopped
    networks:
      - pipe-dragon

networks:
  pipe-dragon:
    driver: bridge